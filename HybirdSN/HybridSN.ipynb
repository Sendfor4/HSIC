{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["##This is a pytorch implement for HybridSN \n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","from torchinfo import summary\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import spectral\n","import random\n","from sklearn.decomposition import PCA\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report,recall_score,cohen_kappa_score,accuracy_score\n","from scipy.io import loadmat\n","import os\n","from tqdm import tqdm\n","%matplotlib inline"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["##hypeperameters and experimental settings\n","RANDOM_SEED=666\n","DATASET = 'PU'    ## PU  IP  SA  \n","TRAIN_RATE = 0.3  ## ratio of training data\n","VAL_RATE = 0.1    ## ratio of valuating data\n","EPOCH = 100    ##number of epoch\n","VAL_EPOCH = 5  ##interval of valuation\n","LR = 0.001    ##learning rate\n","WEIGHT_DECAY = 1e-6  \n","BATCH_SIZE = 256\n","DEVICE = 0  ##-1:CPU  0:cuda 0\n","N_PCA = 15  ## reserved PCA components\n","PATCH_SIZE = 25 \n","SAVE_PATH = f\"results\\\\{DATASET}\"\n","if not os.path.isdir(SAVE_PATH):\n","    os.mkdir(SAVE_PATH)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Set random seed for reproduction\n","random.seed(RANDOM_SEED)\n","torch.manual_seed(RANDOM_SEED)\n","torch.cuda.manual_seed(RANDOM_SEED)\n","torch.cuda.manual_seed_all(RANDOM_SEED)\n","np.random.seed(RANDOM_SEED)\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def loadData(name):\n","    data_path = os.path.join(os.getcwd(),'dataset')\n","    if name == 'IP':\n","        data = loadmat(os.path.join(data_path, 'IndianPines\\\\Indian_pines_corrected.mat'))['indian_pines_corrected']\n","        labels = loadmat(os.path.join(data_path, 'IndianPines\\\\Indian_pines_gt.mat'))['indian_pines_gt']\n","        class_name = [ \"Alfalfa\", \"Corn-notill\", \"Corn-mintill\",\"Corn\", \"Grass-pasture\", \n","                       \"Grass-trees\",\"Grass-pasture-mowed\", \"Hay-windrowed\", \"Oats\",\"Soybean-notill\", \"Soybean-mintill\", \"Soybean-clean\",\"Wheat\", \"Woods\", \"Buildings-Grass-Trees-Drives\",\"Stone-Steel-Towers\"]\n","    elif name == 'SA':\n","        data = loadmat(os.path.join(data_path, 'Salinas\\\\Salinas_corrected.mat'))['salinas_corrected']\n","        labels = loadmat(os.path.join(data_path, 'Salinas\\\\Salinas_gt.mat'))['salinas_gt']\n","        class_name = ['Brocoli_green_weeds_1','Brocoli_green_weeds_2','Fallow',\n","                        'Fallow_rough_plow','Fallow_smooth','Stubble','Celery','Grapes_untrained','Soil_vinyard_develop','Corn_senesced_green','Lettuce_romaine_4wk','Lettuce_romaine_5wk','Lettuce_romaine_6wk','Lettuce_romaine_7wk','Vinyard_untrained','Vinyard_vertical']\n","    elif name == 'PU':\n","        data = loadmat(os.path.join(data_path, 'PaviaU\\\\PaviaU.mat'))['paviaU']\n","        labels = loadmat(os.path.join(data_path, 'PaviaU\\\\PaviaU_gt.mat'))['paviaU_gt']\n","        class_name = ['Asphalt', 'Meadows', 'Gravel', 'Trees','Painted metal sheets', 'Bare Soil', \n","                      'Bitumen','Self-Blocking Bricks', 'Shadows']\n","    return data, labels, class_name\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["data,label,class_name = loadData(DATASET)\n","NUM_CLASS = label.max()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## display HSI\n","rgb_view=spectral.imshow(data,(30,20,10),classes=label,title='RGB origin',figsize=(7,7))\n","gt_view = spectral.imshow(classes=label, title='GroundTruth',figsize=(7,7))\n","view = spectral.imshow(data,(30,20,10),classes=label,figsize=(7,7))\n","view.set_display_mode('overlay')\n","view.class_alpha = 1\n","view.set_title('Overlay')\n","spectral.save_rgb(f'results/{DATASET}_RGB_origin.jpg',data,(30,20,10))\n","spectral.save_rgb(f'results/{DATASET}_gt.jpg',label,colors = spectral.spy_colors)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## show 3D cube\n","# %matplotlib auto\n","# spectral.view_cube(data,(30,20,10))   ## depend on wxpython and pyopengl"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def applyPCA(X, numComponents=15):\n","    \"\"\"PCA processing\n","\n","    Args:\n","        X (ndarray M*N*C): data needs DR\n","        numComponents (int, optional): number of reserved components. Defaults to 15.\n","\n","    Returns:\n","        newX: _description_\n","    \"\"\"\n","    newX = np.reshape(X, (-1, X.shape[2]))\n","    pca = PCA(n_components=numComponents, whiten=True)   ##PCA and normalization\n","    newX = pca.fit_transform(newX)\n","    newX = np.reshape(newX, (X.shape[0],X.shape[1], numComponents))\n","    return newX, pca"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["data,pca = applyPCA(data,40)\n","data.shape"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## display HSI\n","rgb_view=spectral.imshow(data,(30,20,10),classes=label,title='RGB origin',figsize=(7,7))\n","gt_view = spectral.imshow(data,(30,20,10),classes=label, title='GroundTruth',figsize=(7,7))\n","gt_view.set_display_mode('classes')\n","view = spectral.imshow(data,(30,20,10),classes=label,figsize=(7,7))\n","view.set_display_mode('overlay')\n","view.class_alpha = 1\n","view.set_title('Overlay')\n","spectral.save_rgb(f'results/{DATASET}_RGB_origin.jpg',data,(30,20,10))\n","spectral.save_rgb(f'results/{DATASET}_gt.jpg',label,colors = spectral.spy_colors)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## display HSI\n","rgb_view=spectral.imshow(data,(14,10,5),classes=label,title='RGB origin',figsize=(7,7))\n","gt_view = spectral.imshow(data, bands = (14,10,5), classes=label, title='GroundTruth',figsize=(7,7))\n","view = spectral.imshow(data,(14,10,5),classes=label,figsize=(7,7))\n","view.set_display_mode('overlay')\n","view.class_alpha = 1\n","view.set_title('Overlay')\n","spectral.save_rgb(f'results/{DATASET}_RGB_origin.jpg',data,(14,10,5))\n","spectral.save_rgb(f'results/{DATASET}_gt.jpg',label,colors = spectral.spy_colors)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def sample_gt(gt, train_rate):\n","    \"\"\" generate training gt for training dataset\n","    Args:\n","        gt (ndarray): full classmap\n","        train_rate (float): ratio of training dataset\n","    Returns:\n","        train_gt(ndarray): classmap of training data\n","        test_gt(ndarray): classmap of test data\n","    \"\"\"\n","    print(gt)\n","    print('--------------------------------------')\n","    indices = np.nonzero(gt)  ##([x1,x2,...],[y1,y2,...]) 获取非零元素的行索引和列索引\n","    print(indices)\n","    print('--------------------------------------')\n","    X = list(zip(*indices))  ## X=[(x1,y1),(x2,y2),...] location of pixels 定位到各元素的坐标\n","    y = gt[indices].ravel()  #  获取对应于非零索引的类图值，并将其展平\n","    print(y)\n","    print(y.max())\n","    print('--------------------------------------')\n","    \n","    train_gt = np.zeros_like(gt)  # 创建一个与gt形状相同，但元素全为零的数组，用于存储训练类图\n","    test_gt = np.zeros_like(gt)\n","    if train_rate > 1:\n","       train_rate = int(train_rate)\n","    train_indices, test_indices = train_test_split(X, train_size=train_rate, stratify=y, random_state=100)\n","    print(train_indices)\n","    print('以上为train_indices --------------------------------------')\n","    train_indices = [t for t in zip(*train_indices)]   ##[[x1,x2,...],[y1,y2,...]] \n","    test_indices = [t for t in zip(*test_indices)]   # 将测试索引转换为[[x1,x2,...],[y1,y2,...]]的格式。一次性访问多个元素\n","    print(train_indices)\n","    print('以上为train_indices --------------------------------------')\n","    print(tuple(train_indices))\n","    print('以上为tuple(train_indices)------')\n","    train_gt[tuple(train_indices)] = gt[tuple(train_indices)]\n","    test_gt[tuple(test_indices)] = gt[tuple(test_indices)]\n","    print(gt[tuple(train_indices)])\n","    print('以上为gt[tuple(train_indices)]------')\n","    print(train_gt)\n","    print('以上为train_gt--------------------------------------')\n","    \n","    return train_gt, test_gt"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["train_gt, test_gt = sample_gt(label,TRAIN_RATE)\n","val_gt,test_gt = sample_gt(test_gt,VAL_RATE/(1-TRAIN_RATE))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## display sampling info\n","sample_report = f\"{'class': ^10}{'train_num':^10}{'val_num': ^10}{'test_num': ^10}{'total': ^10}\\n\"\n","for i in np.unique(label):\n","    if i == 0: continue\n","    sample_report += f\"{i: ^10}{(train_gt==i).sum(): ^10}{(val_gt==i).sum(): ^10}{(test_gt==i).sum(): ^10}{(label==i).sum(): ^10}\\n\"\n","sample_report += f\"{'total': ^10}{np.count_nonzero(train_gt): ^10}{np.count_nonzero(val_gt): ^10}{np.count_nonzero(test_gt): ^10}{np.count_nonzero(label): ^10}\"\n","print(sample_report)\n","spectral.imshow(classes=train_gt, title='train_gt')\n","spectral.imshow(classes=val_gt, title='val_gt')\n","spectral.imshow(classes=test_gt, title='test_gt')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class PatchSet(Dataset):\n","    \"\"\" Generate 3D patch from hyperspectral dataset \"\"\"\n","    def __init__(self, data, gt, patch_size, is_pred=False):\n","        \"\"\"\n","        Args:\n","            data: 3D hyperspectral image\n","            gt: 2D array of labels\n","            patch_size: int, size of the 3D patch\n","            is_pred: bool, create data without label for prediction (default False) \n","\n","        \"\"\"\n","        super(PatchSet, self).__init__()\n","        self.is_pred = is_pred\n","        self.patch_size = patch_size\n","        p = self.patch_size // 2\n","        self.data = np.pad(data,((p,p),(p,p),(0,0)),'constant',constant_values = 0)\n","        if is_pred:\n","            gt = np.ones_like(gt)\n","        self.label = np.pad(gt,(p,p),'constant',constant_values = 0)\n","        x_pos, y_pos = np.nonzero(gt)\n","        x_pos, y_pos = x_pos + p, y_pos + p   ##indices after padding\n","        self.indices = np.array([(x,y) for x,y in zip(x_pos, y_pos)])\n","        if not is_pred:\n","            np.random.shuffle(self.indices)\n","\n","    def __len__(self):\n","        return len(self.indices)\n","\n","    def __getitem__(self, i):\n","        x, y = self.indices[i]\n","        x1, y1 = x - self.patch_size // 2, y - self.patch_size // 2\n","        x2, y2 = x1 + self.patch_size, y1 + self.patch_size\n","        data = self.data[x1:x2, y1:y2]\n","        label = self.label[x, y]\n","        data = np.asarray(data, dtype='float32').transpose((2, 0, 1))\n","        label = np.asarray(label, dtype='int64')\n","        data = torch.from_numpy(data)\n","        label = torch.from_numpy(label)\n","        if self.is_pred:\n","            return data\n","        else: return data, label\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["##create dataset and dataloader\n","train_data = PatchSet(data, train_gt, PATCH_SIZE)\n","val_data = PatchSet(data, val_gt, PATCH_SIZE)\n","all_data = PatchSet(data, label, PATCH_SIZE,is_pred = True)\n","train_loader = DataLoader(train_data,BATCH_SIZE,shuffle= True)\n","val_loader = DataLoader(val_data,BATCH_SIZE,shuffle= True)\n","all_loader = DataLoader(all_data,BATCH_SIZE,shuffle= False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["d,g=train_data.__getitem__(0)\n","d.shape,g"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Defination of HybridSN\n","class HybridSN(nn.Module):\n","    def __init__(self, in_chs, patch_size, class_nums):\n","        super().__init__()\n","        self.in_chs = in_chs\n","        self.patch_size = patch_size\n","        self.conv1 = nn.Sequential(\n","                    nn.Conv3d(in_channels=1,out_channels=8,kernel_size=(7, 3, 3)),\n","                    nn.ReLU(inplace=True))\n","        self.conv2 = nn.Sequential(\n","                    nn.Conv3d(in_channels=8,out_channels=16,kernel_size=(5, 3, 3)),\n","                    nn.ReLU(inplace=True))\n","        self.conv3 = nn.Sequential(\n","                    nn.Conv3d(in_channels=16,out_channels=32,kernel_size=(3, 3, 3)),\n","                    nn.ReLU(inplace=True))\n","        \n","        self.x1_shape = self.get_shape_after_3dconv()\n","        # print(self.x1_shape)\n","        self.conv4 = nn.Sequential(\n","                    nn.Conv2d(in_channels=self.x1_shape[1]*self.x1_shape[2],out_channels=64,kernel_size=(3, 3)),\n","                    nn.ReLU(inplace=True))\n","        self.x2_shape = self.get_shape_after_2dconv()\n","        # print(self.x2_shape)\n","        self.dense1 = nn.Sequential(\n","                    nn.Linear(self.x2_shape,256),\n","                    nn.ReLU(inplace=True),\n","                    nn.Dropout(p=0.4))\n","        \n","        self.dense2 = nn.Sequential(\n","                    nn.Linear(256,128),\n","                    nn.ReLU(inplace=True),\n","                    nn.Dropout(p=0.4))\n","        \n","        self.dense3 = nn.Sequential(\n","                    nn.Linear(128,class_nums)\n","                   )\n","    \n","    def get_shape_after_2dconv(self):\n","        x = torch.zeros((1, self.x1_shape[1]*self.x1_shape[2], self.x1_shape[3], self.x1_shape[4]))\n","        with torch.no_grad():\n","            x = self.conv4(x)\n","            print\n","        return x.shape[1]*x.shape[2]*x.shape[3]\n","    \n","    def get_shape_after_3dconv(self):\n","        x = torch.zeros((1, 1, self.in_chs, self.patch_size, self.patch_size))\n","        with torch.no_grad():\n","            x = self.conv1(x)\n","            x = self.conv2(x)\n","            x = self.conv3(x)\n","        return x.shape\n","    \n","    def forward(self, X):\n","        X = X.unsqueeze(1)\n","        x = self.conv1(X)\n","        x = self.conv2(x)\n","        x = self.conv3(x)\n","        x = x.view(x.shape[0],x.shape[1]*x.shape[2],x.shape[3],x.shape[4])\n","        # print(x.shape)\n","        x = self.conv4(x)\n","        x = x.contiguous().view(x.shape[0], -1)\n","        # print(x.shape)\n","        x = self.dense1(x)\n","        x = self.dense2(x)\n","        out = self.dense3(x)\n","        return out\n","\n","\n","net = HybridSN(N_PCA,PATCH_SIZE,class_nums=NUM_CLASS)\n","summary(net, input_size=(1,N_PCA,PATCH_SIZE,PATCH_SIZE),col_names=['num_params','kernel_size','mult_adds','input_size','output_size'],col_width=10,row_settings=['var_names'],depth=4)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## training the model\n","device = torch.device(DEVICE if DEVICE>=0 and torch.cuda.is_available() else 'cpu')\n","loss_list = []\n","acc_list = []\n","val_acc_list = []\n","val_epoch_list = []\n","\n","model = HybridSN(N_PCA,PATCH_SIZE,class_nums=NUM_CLASS)\n","model.to(device)\n","optimizer = torch.optim.Adam(model.parameters(),LR,weight_decay=WEIGHT_DECAY)\n","loss_func = nn.CrossEntropyLoss()\n","batch_num = len(train_loader)\n","train_num = train_loader.dataset.__len__()\n","val_num = val_loader.dataset.__len__()\n","\n","fig = plt.figure()\n","ax1 = fig.add_subplot(2,1,1)\n","ax2 = fig.add_subplot(2,1,2)\n","try:\n","    for e in tqdm(range(EPOCH), desc=\"Training:\"):\n","        model.train()\n","        avg_loss = 0.\n","        train_acc = 0\n","        for batch_idx, (data, target) in tqdm(enumerate(train_loader),total=batch_num):\n","            data,target = data.to(device),target.to(device)\n","            optimizer.zero_grad()\n","            out = model(data)\n","            target = target - 1  ## class 0 in out is class 1 in target\n","            loss = loss_func(out,target)\n","            loss.backward()\n","            optimizer.step()\n","            avg_loss += loss.item()\n","            _,pred = torch.max(out,dim=1)\n","            train_acc += (pred == target).sum().item()\n","        loss_list.append(avg_loss/train_num)\n","        acc_list.append(train_acc/train_num)\n","        print(f\"epoch {e}/{EPOCH} loss:{loss_list[e]}  acc:{acc_list[e]}\")\n","        ## valuation\n","        if (e+1)%VAL_EPOCH == 0 or (e+1)==EPOCH:\n","            val_acc =0\n","            model.eval()\n","            for batch_idx, (data, target) in tqdm(enumerate(val_loader),total=len(val_loader)):\n","                data,target = data.to(device),target.to(device)\n","                out = model(data)\n","                target = target - 1  ## class 0 in out is class 1 in target\n","                _,pred = torch.max(out,dim=1)\n","                val_acc += (pred == target).sum().item()\n","            val_acc_list.append(val_acc/val_num)\n","            val_epoch_list.append(e)\n","            print(f\"epoch {e}/{EPOCH}  val_acc:{val_acc_list[-1]}\")\n","            save_name = os.path.join(SAVE_PATH, f\"epoch_{e}_acc_{val_acc_list[-1]:.4f}.pth\")\n","            torch.save(model.state_dict(),save_name)\n","    ax1.plot(np.arange(e+1),loss_list)\n","    ax1.set_title('loss')\n","    ax1.set_xlabel('epoch')\n","    ax2.plot(np.arange(e+1),acc_list,label = 'train_acc')\n","    ax2.plot(val_epoch_list,val_acc_list,label = 'val_acc')\n","    ax2.set_title('acc')\n","    ax2.set_xlabel('epoch')\n","    ax2.legend()\n","except Exception as exc:\n","    print(exc)\n","finally: \n","    print(f'Stop in epoch {e}')\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## get best model path and del other models\n","def get_best_model(acc_list, epoch_list, save_path):\n","    \"\"\"get best model path by valuation list\n","\n","    Args:\n","        acc_list (list): list of valuation accuracy\n","        epoch_list (list): list of valuation epoch\n","        save_path (str): path of save dir\n","\n","    Returns:\n","        best_model_path: path of best model\n","    \"\"\"\n","    acc_list = np.array(acc_list)\n","    epoch_list = np.array(epoch_list)\n","    best_index = np.argwhere(acc_list==np.max(acc_list))[-1].item()\n","    best_epoch = epoch_list[best_index]\n","    best_acc = acc_list[best_index]\n","    file_name = f\"epoch_{best_epoch}_acc_{best_acc:.4f}.pth\"\n","    best_model_path=os.path.join(save_path, file_name)\n","    print(f\"best model:{file_name}\")\n","    ##del save model except best model\n","    for f in os.listdir(save_path):\n","        if f[-3:]=='pth' and os.path.join(save_path,f)!=best_model_path:\n","            os.remove(os.path.join(save_path,f))\n","    return best_model_path"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## inferring the whole image\n","##load best model\n","best_model_path = get_best_model(val_acc_list,val_epoch_list,SAVE_PATH)\n","best_model = HybridSN(N_PCA,PATCH_SIZE,class_nums=NUM_CLASS)\n","best_model.load_state_dict(torch.load(best_model_path))\n","## inference\n","best_model.to(device)\n","best_model.eval()\n","pred_map = []\n","for batch_idx, data in tqdm(enumerate(all_loader),total=len(all_loader)):\n","    data = data.to(device)\n","    target = best_model(data)\n","    _, pred = torch.max(target, dim = 1)\n","    pred_map += [np.array(pred.detach().cpu() + 1)]   ## class 0 in pred_map is class 1 in gt\n","pred_map = np.asarray(np.hstack(pred_map),dtype=np.uint8).reshape(label.shape[0],label.shape[1])\n","spectral.imshow(classes=pred_map,title='prediction',figsize=(7,7))\n","spectral.imshow(classes=pred_map*(label!=0),title='prediction_masked',figsize=(7,7))\n","spectral.save_rgb(os.path.join(SAVE_PATH,f\"prediction.jpg\"),pred_map,colors = spectral.spy_colors)\n","spectral.save_rgb(os.path.join(SAVE_PATH,f\"prediction_masked.jpg\"),pred_map*(label!=0),colors = spectral.spy_colors)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## classfication report\n","test_pred = pred_map[test_gt!=0]\n","test_true = test_gt[test_gt!=0]\n","\n","OA = accuracy_score(test_true,test_pred)\n","AA = recall_score(test_true,test_pred,average='macro')\n","kappa = cohen_kappa_score(test_true,test_pred)\n","report_log = F\"OA: {OA}\\nAA: {AA}\\nKappa: {kappa}\\n\"\n","report_log += classification_report(test_true,test_pred,target_names=class_name,digits=4)\n","print(report_log)\n","fp = open(os.path.join(SAVE_PATH,'classfication_report.txt'),'w+')\n","fp.writelines(report_log)\n","fp.close()"]}],"metadata":{"interpreter":{"hash":"cf59b85677ef8bbc27ae54bd5fffd1227219dbab0c241877bdfafd2c89938c2d"},"kernelspec":{"display_name":"Python 3.7.11 ('pytorch-gpu')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
